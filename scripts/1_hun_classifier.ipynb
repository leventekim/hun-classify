{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f8521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import huspacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c979d4b9",
   "metadata": {},
   "source": [
    "## 3.1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0a082f",
   "metadata": {},
   "source": [
    "Reading in the files as list of strings with each element of the list being a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56d852f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old documents (before the 16th century)\n",
    "old_files = [f for f in os.listdir('../data/old') if f.endswith('.txt')]\n",
    "old_documents = []\n",
    "for filename in old_files:\n",
    "    with open(os.path.join('../data/old',filename),'r',encoding='utf-8') as f:\n",
    "        old_documents.append(f.read())\n",
    "\n",
    "# new documents (from 20th century)\n",
    "new_files = [f for f in os.listdir('../data/new') if f.endswith('.txt')]\n",
    "new_documents = []\n",
    "for filename in new_files:\n",
    "    with open(os.path.join('../data/new',filename),'r',encoding='utf-8') as f:\n",
    "        new_documents.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6e87bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example document in old Hungarian:\n",
      "Krisztus feltámada , mint ön nagy kínjából asszony , mi is örülünk .\n",
      "Krisztus legyen reményünk .\n",
      "Kyrie eleison \n",
      "------------------------------------------\n",
      "An example document from the 20th century:\n",
      "Nincsen apám, se anyám,\n",
      "se istenem, se hazám,\n",
      "se bölcsőm, se szemfedőm,\n",
      "se csókom, se szeretőm.\n",
      "\n",
      "Harmadnapja nem eszek,\n",
      "se sokat, se keveset.\n",
      "Húsz esztendőm hatalom,\n",
      "húsz esztendőm eladom.\n",
      "\n",
      "Hogyha nem kell senkinek,\n",
      "hát az ördög veszi meg.\n",
      "Tiszta szívvel betörök,\n",
      "ha kell, embert is ölök.\n",
      "\n",
      "Elfognak és felkötnek,\n",
      "áldott földdel elfödnek\n",
      "s halált hozó fű terem\n",
      "gyönyörűszép szívemen.\n"
     ]
    }
   ],
   "source": [
    "# inspecting the results of reading in the files\n",
    "print(\"An example document in old Hungarian:\")\n",
    "print(old_documents[8])\n",
    "print(\"------------------------------------------\")\n",
    "print(\"An example document from the 20th century:\")\n",
    "print(new_documents[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7149bf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Kim\n",
      "[nltk_data]     Levente\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\ProgramData\\\\anaconda3\\\\python.exe', '-m', 'pip', 'install', 'hu_core_news_lg @ https://huggingface.co/huspacy/hu_core_news_lg/resolve/v3.8.0/hu_core_news_lg-any-py3-none-any.whl']\n"
     ]
    }
   ],
   "source": [
    "# download time: 59.3s\n",
    "nltk.download(\"stopwords\")\n",
    "huspacy.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7b5dcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TextPreprocessor(text, nlp):\n",
    "    \"\"\" Preprocesses documents\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text string, document to be cleaned\n",
    "    nlp Spacy Language, pipeline for tokenization\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    text_clean string, cleaned document\n",
    "    \"\"\"\n",
    "    # make text lowercase, replace linebreak with space\n",
    "    text_low = text.lower()\n",
    "    text_low = text_low.replace(\"\\n\",\" \")\n",
    "\n",
    "    # some texts contain indicators of which line the text is at\n",
    "    # in curly brackets\n",
    "    text_low = re.sub(r'\\{[^}]*\\}', '', text_low)\n",
    "\n",
    "    # tokenize the document\n",
    "    tokens = [token.text for token in nlp(text_low)]\n",
    "    \n",
    "    # exclude stopwords and punctuations\n",
    "    stop_words = set(stopwords.words(\"Hungarian\"))\n",
    "    tokens_clean = [word for word in tokens if word not in stop_words and word not in string.punctuation]\n",
    "\n",
    "    # cleaned tokens are joined by space\n",
    "    text_clean = \" \".join(tokens_clean)\n",
    "\n",
    "    return text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "284084ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean texts, runtime: 19.4s\n",
    "nlp_hun = huspacy.load()\n",
    "old_docs_clean = [TextPreprocessor(doc,nlp_hun) for doc in old_documents]\n",
    "new_docs_clean = [TextPreprocessor(doc,nlp_hun) for doc in new_documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae6387e",
   "metadata": {},
   "source": [
    "Inspecting the result of preprocessing an old text and a new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "937a67a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ez vég pusztaságról megemlékeznétek , el ne vesznétek , az régi jó nevet megelevenítenétek , kereszténységnek jó vértei  lennétek .\n",
      "szegény Mátyás király vala békességben , mert országa vala egyességben , vitézek valának nála tisztességben , az urak valának nagy egyenességben .\n",
      "ti Úristen ellen ne háborganátok , régi dekrétumot csak megtartanátok , az dézsmát igazán kiszolgáltatnátok , koronként Istennek vele áldoznátok .\n",
      "Isten , Szűz Mária háborútól védjen , Hatvanban gyűlétek , hogy jó végre legyen , jó Lajos királyunk diadalmat vegyen , minden tanácsotokban ő jó véget tegyen .\n",
      "Pesti Beke Ferenc szíve kétségében , ki az vendég népnek bízik erejében , török császárt töri hízelkedésében , minden ennek ő elvetett beszédében .\n",
      "Geszti László diák szerzé ez éneket , Magyarország vala nagy fő szükségében , az végek valának mind elveszendőben , ezerötszázhuszonöt esztendőben .\n",
      "--------------\n",
      "vég pusztaságról megemlékeznétek vesznétek régi nevet megelevenítenétek kereszténységnek vértei   lennétek szegény mátyás király vala békességben országa vala egyességben vitézek valának nála tisztességben urak valának egyenességben ti úristen háborganátok régi dekrétumot megtartanátok dézsmát igazán kiszolgáltatnátok koronként istennek áldoznátok isten szűz mária háborútól védjen hatvanban gyűlétek végre lajos királyunk diadalmat vegyen tanácsotokban ő véget tegyen pesti beke ferenc szíve kétségében vendég népnek bízik erejében török császárt töri hízelkedésében ő elvetett beszédében geszti lászló diák szerzé éneket magyarország vala fő szükségében végek valának mind elveszendőben ezerötszázhuszonöt esztendőben\n"
     ]
    }
   ],
   "source": [
    "print(old_documents[4])\n",
    "print(\"--------------\")\n",
    "print(old_docs_clean[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c77bbe00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haragszom én arra szóra,\n",
      "Ki a papot úgy megszólja,\n",
      "Mert a papnak nincs bundája,\n",
      "Hideg a reverendája.\n",
      "Heje-huja, hopp!\n",
      "Haragszom én arra szóra,\n",
      "Ki a mestert úgy megszólja;\n",
      "A mesternek nincs kalapja,\n",
      "Sapkában jár az utcára.\n",
      "Heje-huja, hopp!\n",
      "Heje-huja, szűröm ujja!\n",
      "A cigány a nótám fújja.\n",
      "Gyere, rózsám, táncoljunk hát,\n",
      "Járjuk el a magyar nótát!\n",
      "Heje-huja, hopp!\n",
      "--------------\n",
      "haragszom szóra papot megszólja papnak bundája hideg reverendája heje-huja hopp haragszom szóra mestert megszólja mesternek kalapja sapkában jár utcára heje-huja hopp heje-huja szűröm ujja cigány nótám fújja gyere rózsám táncoljunk hát járjuk magyar nótát heje-huja hopp\n"
     ]
    }
   ],
   "source": [
    "print(new_documents[4])\n",
    "print(\"--------------\")\n",
    "print(new_docs_clean[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7945e415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'ahogy',\n",
       " 'ahol',\n",
       " 'aki',\n",
       " 'akik',\n",
       " 'akkor',\n",
       " 'alatt',\n",
       " 'által',\n",
       " 'általában',\n",
       " 'amely',\n",
       " 'amelyek',\n",
       " 'amelyekben',\n",
       " 'amelyeket',\n",
       " 'amelyet',\n",
       " 'amelynek',\n",
       " 'ami',\n",
       " 'amit',\n",
       " 'amolyan',\n",
       " 'amíg',\n",
       " 'amikor']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get example stop words in Hungarian\n",
    "stopwords.words(\"Hungarian\")[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c7b46f",
   "metadata": {},
   "source": [
    "## 3.2. Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e7e7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b244366",
   "metadata": {},
   "source": [
    "## 3.3. Description of Classification Models and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f290a435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
