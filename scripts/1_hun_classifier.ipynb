{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50f8521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import huspacy\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "import gensim\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c979d4b9",
   "metadata": {},
   "source": [
    "## 3.1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0a082f",
   "metadata": {},
   "source": [
    "Reading in the files as list of strings with each element of the list being a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56d852f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old documents (before the 16th century)\n",
    "old_files = [f for f in os.listdir('../data/old') if f.endswith('.txt')]\n",
    "old_documents = []\n",
    "for filename in old_files:\n",
    "    with open(os.path.join('../data/old',filename),'r',encoding='utf-8') as f:\n",
    "        old_documents.append(f.read())\n",
    "\n",
    "# new documents (from 20th century)\n",
    "new_files = [f for f in os.listdir('../data/new') if f.endswith('.txt')]\n",
    "new_documents = []\n",
    "for filename in new_files:\n",
    "    with open(os.path.join('../data/new',filename),'r',encoding='utf-8') as f:\n",
    "        new_documents.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6e87bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example document in old Hungarian:\n",
      "Krisztus feltámada , mint ön nagy kínjából asszony , mi is örülünk .\n",
      "Krisztus legyen reményünk .\n",
      "Kyrie eleison \n",
      "------------------------------------------\n",
      "An example document from the 20th century:\n",
      "Nincsen apám, se anyám,\n",
      "se istenem, se hazám,\n",
      "se bölcsőm, se szemfedőm,\n",
      "se csókom, se szeretőm.\n",
      "\n",
      "Harmadnapja nem eszek,\n",
      "se sokat, se keveset.\n",
      "Húsz esztendőm hatalom,\n",
      "húsz esztendőm eladom.\n",
      "\n",
      "Hogyha nem kell senkinek,\n",
      "hát az ördög veszi meg.\n",
      "Tiszta szívvel betörök,\n",
      "ha kell, embert is ölök.\n",
      "\n",
      "Elfognak és felkötnek,\n",
      "áldott földdel elfödnek\n",
      "s halált hozó fű terem\n",
      "gyönyörűszép szívemen.\n"
     ]
    }
   ],
   "source": [
    "# inspecting the results of reading in the files\n",
    "print(\"An example document in old Hungarian:\")\n",
    "print(old_documents[8])\n",
    "print(\"------------------------------------------\")\n",
    "print(\"An example document from the 20th century:\")\n",
    "print(new_documents[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7149bf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Kim\n",
      "[nltk_data]     Levente\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\ProgramData\\\\anaconda3\\\\python.exe', '-m', 'pip', 'install', 'hu_core_news_lg @ https://huggingface.co/huspacy/hu_core_news_lg/resolve/v3.8.0/hu_core_news_lg-any-py3-none-any.whl']\n"
     ]
    }
   ],
   "source": [
    "# only needs to be run once, download time: 2m 48.4s\n",
    "nltk.download(\"stopwords\")\n",
    "huspacy.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7b5dcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TextPreprocessor(text, nlp):\n",
    "    \"\"\" Preprocesses documents\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text string, document to be cleaned\n",
    "    nlp Spacy Language, pipeline for tokenization\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    text_clean string, cleaned document\n",
    "    \"\"\"\n",
    "    # make text lowercase, replace linebreak with space\n",
    "    text_low = text.lower()\n",
    "    text_low = text_low.replace(\"\\n\",\" \")\n",
    "\n",
    "    # some texts contain indicators of which line the text is at\n",
    "    # in curly brackets\n",
    "    text_low = re.sub(r'\\{[^}]*\\}', '', text_low)\n",
    "\n",
    "    # tokenize the document\n",
    "    tokens = [token.text for token in nlp(text_low)]\n",
    "    \n",
    "    # exclude stopwords and punctuations\n",
    "    stop_words = set(stopwords.words(\"Hungarian\"))\n",
    "    tokens_clean = [word for word in tokens if word not in stop_words and word not in string.punctuation]\n",
    "\n",
    "    # cleaned tokens are joined by space\n",
    "    text_clean = \" \".join(tokens_clean)\n",
    "\n",
    "    return text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284084ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean texts, runtime: < 20s\n",
    "nlp_hun = huspacy.load()\n",
    "old_docs_clean = [TextPreprocessor(doc,nlp_hun) for doc in old_documents]\n",
    "new_docs_clean = [TextPreprocessor(doc,nlp_hun) for doc in new_documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae6387e",
   "metadata": {},
   "source": [
    "Inspecting the result of preprocessing an old text and a new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "937a67a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ez vég pusztaságról megemlékeznétek , el ne vesznétek , az régi jó nevet megelevenítenétek , kereszténységnek jó vértei  lennétek .\n",
      "szegény Mátyás király vala békességben , mert országa vala egyességben , vitézek valának nála tisztességben , az urak valának nagy egyenességben .\n",
      "ti Úristen ellen ne háborganátok , régi dekrétumot csak megtartanátok , az dézsmát igazán kiszolgáltatnátok , koronként Istennek vele áldoznátok .\n",
      "Isten , Szűz Mária háborútól védjen , Hatvanban gyűlétek , hogy jó végre legyen , jó Lajos királyunk diadalmat vegyen , minden tanácsotokban ő jó véget tegyen .\n",
      "Pesti Beke Ferenc szíve kétségében , ki az vendég népnek bízik erejében , török császárt töri hízelkedésében , minden ennek ő elvetett beszédében .\n",
      "Geszti László diák szerzé ez éneket , Magyarország vala nagy fő szükségében , az végek valának mind elveszendőben , ezerötszázhuszonöt esztendőben .\n",
      "--------------\n",
      "vég pusztaságról megemlékeznétek vesznétek régi nevet megelevenítenétek kereszténységnek vértei   lennétek szegény mátyás király vala békességben országa vala egyességben vitézek valának nála tisztességben urak valának egyenességben ti úristen háborganátok régi dekrétumot megtartanátok dézsmát igazán kiszolgáltatnátok koronként istennek áldoznátok isten szűz mária háborútól védjen hatvanban gyűlétek végre lajos királyunk diadalmat vegyen tanácsotokban ő véget tegyen pesti beke ferenc szíve kétségében vendég népnek bízik erejében török császárt töri hízelkedésében ő elvetett beszédében geszti lászló diák szerzé éneket magyarország vala fő szükségében végek valának mind elveszendőben ezerötszázhuszonöt esztendőben\n"
     ]
    }
   ],
   "source": [
    "print(old_documents[4])\n",
    "print(\"--------------\")\n",
    "print(old_docs_clean[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c77bbe00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haragszom én arra szóra,\n",
      "Ki a papot úgy megszólja,\n",
      "Mert a papnak nincs bundája,\n",
      "Hideg a reverendája.\n",
      "Heje-huja, hopp!\n",
      "Haragszom én arra szóra,\n",
      "Ki a mestert úgy megszólja;\n",
      "A mesternek nincs kalapja,\n",
      "Sapkában jár az utcára.\n",
      "Heje-huja, hopp!\n",
      "Heje-huja, szűröm ujja!\n",
      "A cigány a nótám fújja.\n",
      "Gyere, rózsám, táncoljunk hát,\n",
      "Járjuk el a magyar nótát!\n",
      "Heje-huja, hopp!\n",
      "--------------\n",
      "haragszom szóra papot megszólja papnak bundája hideg reverendája heje-huja hopp haragszom szóra mestert megszólja mesternek kalapja sapkában jár utcára heje-huja hopp heje-huja szűröm ujja cigány nótám fújja gyere rózsám táncoljunk hát járjuk magyar nótát heje-huja hopp\n"
     ]
    }
   ],
   "source": [
    "print(new_documents[4])\n",
    "print(\"--------------\")\n",
    "print(new_docs_clean[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7945e415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'ahogy',\n",
       " 'ahol',\n",
       " 'aki',\n",
       " 'akik',\n",
       " 'akkor',\n",
       " 'alatt',\n",
       " 'által',\n",
       " 'általában',\n",
       " 'amely',\n",
       " 'amelyek',\n",
       " 'amelyekben',\n",
       " 'amelyeket',\n",
       " 'amelyet',\n",
       " 'amelynek',\n",
       " 'ami',\n",
       " 'amit',\n",
       " 'amolyan',\n",
       " 'amíg',\n",
       " 'amikor']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get example stop words in Hungarian\n",
    "stopwords.words(\"Hungarian\")[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85d135dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the lists of cleaned docs for further analysis\n",
    "docs_clean = old_docs_clean + new_docs_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c7b46f",
   "metadata": {},
   "source": [
    "## 3.2. Embedding Models\n",
    "### 1. Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e7e7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1 = CountVectorizer(min_df=3)\n",
    "X1_sparse = vectorizer1.fit_transform(docs_clean)\n",
    "\n",
    "# for further analysis, the result is converted to np array\n",
    "X1 = X1_sparse.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5cc5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adatott</th>\n",
       "      <th>anya</th>\n",
       "      <th>asszony</th>\n",
       "      <th>avagy</th>\n",
       "      <th>bús</th>\n",
       "      <th>császár</th>\n",
       "      <th>egyet</th>\n",
       "      <th>egyszer</th>\n",
       "      <th>előtt</th>\n",
       "      <th>ember</th>\n",
       "      <th>...</th>\n",
       "      <th>énnekem</th>\n",
       "      <th>értem</th>\n",
       "      <th>ím</th>\n",
       "      <th>óriás</th>\n",
       "      <th>ön</th>\n",
       "      <th>ördög</th>\n",
       "      <th>úr</th>\n",
       "      <th>út</th>\n",
       "      <th>ők</th>\n",
       "      <th>őt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adatott  anya  asszony  avagy  bús  császár  egyet  egyszer  előtt  ember  \\\n",
       "0        0     0        0      0    0        0      0        0      0      0   \n",
       "1        0     0        0      0    0        0      0        0      0      0   \n",
       "2        0     0        0      0    0        0      0        0      1      0   \n",
       "3        0     0        0      0    0        1      0        0      0      0   \n",
       "4        0     0        0      0    0        0      0        0      0      0   \n",
       "\n",
       "   ...  énnekem  értem  ím  óriás  ön  ördög  úr  út  ők  őt  \n",
       "0  ...        0      0   0      0   0      0   0   1   0   0  \n",
       "1  ...        0      0   0      0   1      0   0   0   0   0  \n",
       "2  ...        0      0   0      0   0      0   0   0   6   2  \n",
       "3  ...        0      0   0      0   0      0   0   0   0   0  \n",
       "4  ...        0      0   0      0   0      0   0   0   0   0  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check results of count vectorization\n",
    "res1 = pd.DataFrame(X1,\n",
    "             columns=vectorizer1.get_feature_names_out())\n",
    "res1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a281e0",
   "metadata": {},
   "source": [
    "### 2.TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38e0b12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = TfidfVectorizer(min_df=3)\n",
    "X2_sparse = vectorizer2.fit_transform(docs_clean)\n",
    "\n",
    "# for further analysis, the result is converted to np array\n",
    "X2 = X2_sparse.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f7a69fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adatott</th>\n",
       "      <th>anya</th>\n",
       "      <th>asszony</th>\n",
       "      <th>avagy</th>\n",
       "      <th>bús</th>\n",
       "      <th>császár</th>\n",
       "      <th>egyet</th>\n",
       "      <th>egyszer</th>\n",
       "      <th>előtt</th>\n",
       "      <th>ember</th>\n",
       "      <th>...</th>\n",
       "      <th>énnekem</th>\n",
       "      <th>értem</th>\n",
       "      <th>ím</th>\n",
       "      <th>óriás</th>\n",
       "      <th>ön</th>\n",
       "      <th>ördög</th>\n",
       "      <th>úr</th>\n",
       "      <th>út</th>\n",
       "      <th>ők</th>\n",
       "      <th>őt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098056</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.251926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.39226</td>\n",
       "      <td>0.116993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adatott  anya  asszony  avagy  bús   császár  egyet  egyszer     előtt  \\\n",
       "0      0.0   0.0      0.0    0.0  0.0  0.000000    0.0      0.0  0.000000   \n",
       "1      0.0   0.0      0.0    0.0  0.0  0.000000    0.0      0.0  0.000000   \n",
       "2      0.0   0.0      0.0    0.0  0.0  0.000000    0.0      0.0  0.065377   \n",
       "3      0.0   0.0      0.0    0.0  0.0  0.147517    0.0      0.0  0.000000   \n",
       "4      0.0   0.0      0.0    0.0  0.0  0.000000    0.0      0.0  0.000000   \n",
       "\n",
       "   ember  ...  énnekem  értem   ím  óriás        ön  ördög   úr        út  \\\n",
       "0    0.0  ...      0.0    0.0  0.0    0.0  0.000000    0.0  0.0  0.098056   \n",
       "1    0.0  ...      0.0    0.0  0.0    0.0  0.251926    0.0  0.0  0.000000   \n",
       "2    0.0  ...      0.0    0.0  0.0    0.0  0.000000    0.0  0.0  0.000000   \n",
       "3    0.0  ...      0.0    0.0  0.0    0.0  0.000000    0.0  0.0  0.000000   \n",
       "4    0.0  ...      0.0    0.0  0.0    0.0  0.000000    0.0  0.0  0.000000   \n",
       "\n",
       "        ők        őt  \n",
       "0  0.00000  0.000000  \n",
       "1  0.00000  0.000000  \n",
       "2  0.39226  0.116993  \n",
       "3  0.00000  0.000000  \n",
       "4  0.00000  0.000000  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check results\n",
    "res2 = pd.DataFrame(X2,\n",
    "             columns=vectorizer2.get_feature_names_out())\n",
    "res2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca644239",
   "metadata": {},
   "source": [
    "### 3.Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8131317b",
   "metadata": {},
   "source": [
    "Tokenize documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe77518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for doc in docs_clean:\n",
    "    tokens_doc = [token.text for token in nlp_hun(doc)]\n",
    "    tokens.append(tokens_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c10a73e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = gensim.models.Word2Vec(tokens, min_count=3,\n",
    "                                vector_size=100, window=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67a2ae2",
   "metadata": {},
   "source": [
    "To obtain a vector for each document, the average vector is taken for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e721ba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_to_vec(doc, model, nlp):\n",
    "    \"\"\" Create vectorization of document\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc string, document\n",
    "    model gensim model, trained Gensim embedding model\n",
    "    nlp Spacy Language, pipeline for tokenization\n",
    "    \"\"\"\n",
    "    doc_tokenized = [token.text for token in nlp(doc)]\n",
    "    vectors_doc = [model.wv[word] for word in doc_tokenized if word in model.wv]\n",
    "    if vectors_doc:\n",
    "        return np.mean(vectors_doc,axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1f9a61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = np.array([doc_to_vec(doc, model3, nlp_hun) for doc in docs_clean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "20366d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.002244</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>-0.000537</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>-0.005622</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>-0.006457</td>\n",
       "      <td>-0.002318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003732</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.006025</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>0.006030</td>\n",
       "      <td>-0.007116</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>-0.002375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.003693</td>\n",
       "      <td>-0.000373</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.004965</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>-0.003049</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.007668</td>\n",
       "      <td>-0.001398</td>\n",
       "      <td>-0.003745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003970</td>\n",
       "      <td>0.003533</td>\n",
       "      <td>-0.000111</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>0.006953</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>-0.003545</td>\n",
       "      <td>-0.001128</td>\n",
       "      <td>-0.001213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000736</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>-0.001203</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>-0.004858</td>\n",
       "      <td>0.003722</td>\n",
       "      <td>0.006906</td>\n",
       "      <td>-0.003368</td>\n",
       "      <td>-0.002369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005016</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>-0.001016</td>\n",
       "      <td>-0.000841</td>\n",
       "      <td>0.004749</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.005285</td>\n",
       "      <td>-0.002883</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>-0.002530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.003605</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>-0.000110</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>-0.007405</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.008053</td>\n",
       "      <td>-0.001886</td>\n",
       "      <td>-0.004451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004590</td>\n",
       "      <td>0.002568</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>-0.001041</td>\n",
       "      <td>0.004756</td>\n",
       "      <td>0.005816</td>\n",
       "      <td>0.004995</td>\n",
       "      <td>-0.003899</td>\n",
       "      <td>-0.002730</td>\n",
       "      <td>-0.000988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.001873</td>\n",
       "      <td>0.005404</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>-0.006440</td>\n",
       "      <td>0.004461</td>\n",
       "      <td>0.009583</td>\n",
       "      <td>-0.004795</td>\n",
       "      <td>-0.002811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.003881</td>\n",
       "      <td>-0.000142</td>\n",
       "      <td>-0.001175</td>\n",
       "      <td>0.006528</td>\n",
       "      <td>0.005194</td>\n",
       "      <td>0.004814</td>\n",
       "      <td>-0.003809</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>-0.000324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.002244  0.001623 -0.000537  0.001316  0.003629 -0.005622  0.003781   \n",
       "1 -0.003693 -0.000373  0.002138  0.004965  0.002197 -0.003049  0.001486   \n",
       "2 -0.000736  0.002211  0.000620 -0.001203  0.000775 -0.004858  0.003722   \n",
       "3 -0.003605  0.001556  0.000164 -0.000110  0.002121 -0.007405  0.001435   \n",
       "4 -0.001873  0.005404  0.001668  0.000284  0.002191 -0.006440  0.004461   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0  0.007980 -0.006457 -0.002318  ...  0.003732  0.002547  0.000390  0.001084   \n",
       "1  0.007668 -0.001398 -0.003745  ...  0.003970  0.003533 -0.000111  0.003653   \n",
       "2  0.006906 -0.003368 -0.002369  ...  0.005016  0.001820 -0.001016 -0.000841   \n",
       "3  0.008053 -0.001886 -0.004451  ...  0.004590  0.002568  0.000543 -0.001041   \n",
       "4  0.009583 -0.004795 -0.002811  ...  0.004487  0.003881 -0.000142 -0.001175   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0  0.006025  0.004052  0.006030 -0.007116  0.000481 -0.002375  \n",
       "1  0.002671  0.006953  0.000796 -0.003545 -0.001128 -0.001213  \n",
       "2  0.004749  0.003226  0.005285 -0.002883  0.000840 -0.002530  \n",
       "3  0.004756  0.005816  0.004995 -0.003899 -0.002730 -0.000988  \n",
       "4  0.006528  0.005194  0.004814 -0.003809  0.002161 -0.000324  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check results\n",
    "res3 = pd.DataFrame(X3)\n",
    "res3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b244366",
   "metadata": {},
   "source": [
    "## 3.3. Description of Classification Models and Results\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a1d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target is defined as 1 if old and 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f290a435",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X in [X1,X2,X3]:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91462a4",
   "metadata": {},
   "source": [
    "### KNN (K-nearest neighbours algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258e95b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
